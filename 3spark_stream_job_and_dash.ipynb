{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849f23fc-cf57-4a38-a50e-fa61b5088064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add492e5-0c8b-4b93-9d20-97dfda444c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 21:33:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/02 21:33:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# define a function to compute sentiments of the received tweets\n",
    "from pyspark.ml import PipelineModel\n",
    "pipelineFit=PipelineModel.load(\"preprocessingAndLR\")\n",
    "pipelineFitBBC=PipelineModel.load(\"preprocessingAndCategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff842fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_773ac326d34e\n"
     ]
    }
   ],
   "source": [
    "print(pipelineFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f454853e-9f7e-4187-9fe7-539fa85ada05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 21:33:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/05/02 21:33:26 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n",
      "23/05/02 21:33:26 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/ny/vz9x996d1tsb28njj8vbv9fw0000gn/T/temporary-3998a465-07c1-437d-ac6c-6352ca6b2a82. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/05/02 21:33:26 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "----- streaming is running -------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, split, explode, when\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "\n",
    "    # read the tweet data from socket\n",
    "    tweet_daf = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"socket\") \\\n",
    "        .option(\"host\", \"0.0.0.0\") \\\n",
    "        .option(\"port\", 5005) \\\n",
    "        .load()\n",
    "\n",
    "    # type cast the column value\n",
    "tweet_df = tweet_daf.select(explode(split(col(\"value\"), \"TWEET__AN,\")).alias(\"value\"))\n",
    "tweet_df_string = (tweet_df.withColumn('tweet', split(tweet_df['value'], '____SEP,').getItem(0)).withColumn('location', split(tweet_df['value'], '____SEP,').getItem(1)).withColumn('favorites', split(tweet_df['value'], '____SEP,').getItem(2)).withColumn('followers', split(tweet_df['value'], '____SEP,').getItem(3)).withColumn('timestamp', split(tweet_df['value'], '____SEP,').getItem(4)).withColumn('name', split(tweet_df['value'], '____SEP,').getItem(5)))\n",
    "    \n",
    "tweet_df_string =tweet_df_string.drop(\"value\")\n",
    "tweet_df_sentiment = pipelineFit.transform(tweet_df_string).drop(\"tokens\",\"filtered_words\",\"vector\",\"rawPrediction\",\"probability\")\n",
    "tweet_df_sentiment=tweet_df_sentiment.withColumnRenamed(\"prediction\",\"sentiment\")\n",
    "tweet_df_fl = pipelineFitBBC.transform(tweet_df_sentiment).drop(\"tokens\",\"filtered_words\",\"vector\",\"rawPrediction\",\"probability\",\"cf\")\n",
    "tweet_df_fl = tweet_df_fl.withColumn(\"favorites\",col(\"favorites\").cast(\"int\")+1)\n",
    "tweet_df_fl = tweet_df_fl.withColumn(\"followers\",col(\"followers\").cast(\"int\"))\n",
    "tweet_df_fl = tweet_df_fl.withColumn(\"prediction\", when(tweet_df_fl.prediction == 0,\"tech\") \\\n",
    "          .when(tweet_df_fl.prediction == 1,\"business\").when(tweet_df_fl.prediction == 2,\"politics\").when(tweet_df_fl.prediction == 3,\"sport\").when(tweet_df_fl.prediction == 4,\"entertainment\").otherwise(\"Null\"))\n",
    "tweet_df_fl = tweet_df_fl.withColumn(\"sentiment\", when(tweet_df_fl.sentiment == 0.0,\"Negative\") .when(tweet_df_fl.sentiment == 4.0,\"Positive\").otherwise(\"Null\"))\n",
    "    \n",
    "    # write the above data into memory. consider the entire analysis in all iteration (output mode = complete). and let the trigger runs in every 2 secs.\n",
    "writeTweet = tweet_df_fl.writeStream.format(\"memory\").outputMode(\"append\").queryName(\"processed\").trigger(processingTime ='30 seconds').start()\n",
    "print(\"----- streaming is running -------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11a7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4925906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = spark.sql(\"select * from processed where tweet!=''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea913139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4278d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de00b7eb-9f60-47c7-9125-0a89b6929b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (5.13.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from plotly) (8.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf4e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4019ba9a-7b02-429d-ae63-3b28914357d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash==0.29.0\n",
      "  Using cached dash-0.29.0-py3-none-any.whl\n",
      "Requirement already satisfied: Flask>=0.12 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash==0.29.0) (2.2.3)\n",
      "Requirement already satisfied: dash-renderer in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash==0.29.0) (1.9.1)\n",
      "Requirement already satisfied: flask-compress in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash==0.29.0) (1.13)\n",
      "Requirement already satisfied: plotly in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash==0.29.0) (5.13.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=0.12->dash==0.29.0) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=0.12->dash==0.29.0) (2.2.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=0.12->dash==0.29.0) (4.12.0)\n",
      "Requirement already satisfied: click>=8.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=0.12->dash==0.29.0) (8.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=0.12->dash==0.29.0) (3.1.2)\n",
      "Requirement already satisfied: brotli in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from flask-compress->dash==0.29.0) (1.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from plotly->dash==0.29.0) (8.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from importlib-metadata>=3.6.0->Flask>=0.12->dash==0.29.0) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Jinja2>=3.0->Flask>=0.12->dash==0.29.0) (2.1.1)\n",
      "Installing collected packages: dash\n",
      "  Attempting uninstall: dash\n",
      "    Found existing installation: dash 2.9.3\n",
      "    Uninstalling dash-2.9.3:\n",
      "      Successfully uninstalled dash-2.9.3\n",
      "Successfully installed dash-0.29.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dash==0.29.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543ab365-1a59-4104-bda3-26b0c7d92424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash-core-components in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: dash in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (0.29.0)\n",
      "Collecting dash\n",
      "  Using cached dash-2.9.3-py3-none-any.whl (10.2 MB)\n",
      "Requirement already satisfied: dash-core-components in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: dash-html-components in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: dash-renderer in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (1.9.1)\n",
      "Requirement already satisfied: Flask>=1.0.4 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash) (2.2.3)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from dash) (5.13.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=1.0.4->dash) (2.1.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=1.0.4->dash) (4.12.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=1.0.4->dash) (8.1.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Flask>=1.0.4->dash) (2.2.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from plotly>=5.0.0->dash) (8.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vijay_vbr/miniforge3/lib/python3.9/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash) (2.1.1)\n",
      "Installing collected packages: dash\n",
      "  Attempting uninstall: dash\n",
      "    Found existing installation: dash 0.29.0\n",
      "    Uninstalling dash-0.29.0:\n",
      "      Successfully uninstalled dash-0.29.0\n",
      "Successfully installed dash-2.9.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dash-core-components\n",
    "!pip install --upgrade dash dash-core-components dash-html-components dash-renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1258694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  0 non-null      object\n",
      " 1   count      0 non-null      int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 124.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.express as px\n",
    "PORT = 5005\n",
    "data = spark.sql(\"select * from processed\").groupBy(\"sentiment\").count().toPandas()\n",
    "\n",
    "data.info()\n",
    "#data.info()\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div(\n",
    "    children=[\n",
    "        html.H1(children=\"LIVE DASHBOARD\",),\n",
    "        html.H3(children=\"Top 3 Tweets From Most Influenced People on live\",)\n",
    "        , dcc.Interval('userwithtopfollwers-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='userwithtopfollwers-graph'),\n",
    "        html.H3(children=\"Top 3 liked Tweets on live\",),\n",
    "        dcc.Interval('tweetwithtoplikes-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='tweetwithtoplikes-graph'),\n",
    "        \n",
    "        html.H3(children=\"Overall Positive and Negative tweets classification\",),\n",
    "        dcc.Interval('sentiment-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='sentiment-graph'),\n",
    "        \n",
    "        html.H3(children=\"Overall Tweets in each Category\",),\n",
    "        dcc.Interval('category-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='category-graph'),\n",
    "        \n",
    "        html.H3(children=\"Overall Positive and Negative Tweets in each Category\",),\n",
    "        dcc.Interval('sentiment-category-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='sentiment-category-graph'),\n",
    "        \n",
    "        html.H3(children=\"Total likes for Tweets based on Sentiment\",),\n",
    "        dcc.Interval('weight-graph-update', interval = 20000, n_intervals = 0),\n",
    "        dcc.Graph(id='weight-graph'),\n",
    "       \n",
    "        \n",
    "    ]\n",
    ")\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('sentiment-graph','figure'),\n",
    "        [dash.dependencies.Input('sentiment-graph-update', 'n_intervals')])\n",
    "def display_structure(n):\n",
    "    df = spark.sql(\"select * from processed where tweet!=''\").groupBy(\"sentiment\").count().toPandas()\n",
    "    fig = px.bar(df, x=\"sentiment\", y=\"count\")\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('category-graph','figure'),\n",
    "        [dash.dependencies.Input('category-graph-update', 'n_intervals')])\n",
    "def display_structure_2(n):\n",
    "    df = spark.sql(\"select * from processed where tweet!=''\").groupBy(\"prediction\").count().toPandas()\n",
    "    fig = px.pie(df, values='count', names='prediction',)\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('sentiment-category-graph','figure'),\n",
    "        [dash.dependencies.Input('sentiment-category-graph-update', 'n_intervals')])\n",
    "def display_structure_3(n):\n",
    "    df = spark.sql(\"select * from processed where tweet!=''\").groupBy(\"sentiment\",\"prediction\").count().toPandas()\n",
    "    fig = px.bar(df, x=\"prediction\", y=\"count\", color=\"sentiment\",title=\"Overall Positive and Negative Tweets in each Category\")\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('weight-graph','figure'),\n",
    "        [dash.dependencies.Input('weight-graph-update', 'n_intervals')])\n",
    "def display_structure_4(n):\n",
    "    df = spark.sql(\"select sentiment,count(favorites) as count from processed where tweet!='' group by sentiment\").toPandas()\n",
    "    #df = df.groupby(\"sentiment\").favorites.sum()\n",
    "    #fig = px.bar(df, x=\"favorites\", y=\"followers\")\n",
    "    fig = px.bar(df,x=\"sentiment\",y=\"count\", color=\"sentiment\", title=\"Total likes for Tweets based on Sentiment\")\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('userwithtopfollwers-graph','figure'),\n",
    "        [dash.dependencies.Input('userwithtopfollwers-graph-update', 'n_intervals')])\n",
    "def display_structure_5(n):\n",
    "    df = tweetPandas=spark.sql(\"select tweet,name,sentiment,followers from processed where tweet!='' order by followers desc limit 3\").toPandas()\n",
    "    #df = df.groupby(\"sentiment\").favorites.sum()\n",
    "    #fig = px.bar(df, x=\"favorites\", y=\"followers\")\n",
    "    fig = go.Figure(data=[go.Table(header=dict(values=list(df.columns),fill_color='paleturquoise',align='left'),cells=dict(values=[df.tweet, df.name, df.sentiment, df.followers],fill_color='lavender',align='left'))])\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "        dash.dependencies.Output('tweetwithtoplikes-graph','figure'),\n",
    "        [dash.dependencies.Input('tweetwithtoplikes-graph-update', 'n_intervals')])\n",
    "def display_structure_6(n):\n",
    "    df = tweetPandas=spark.sql(\"select tweet,name,sentiment,favorites from processed where tweet!='' order by favorites desc limit 3\").toPandas()\n",
    "    #df = df.groupby(\"sentiment\").favorites.sum()\n",
    "    #fig = px.bar(df, x=\"favorites\", y=\"followers\")\n",
    "    fig = go.Figure(data=[go.Table(header=dict(values=list(df.columns),fill_color='paleturquoise',align='left'),cells=dict(values=[df.tweet, df.name, df.sentiment, df.favorites],fill_color='lavender',align='left'))])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:5005/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dash.dash:Dash is running on http://127.0.0.1:5005/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5005\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(\n",
    "        port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68ddc0-0f34-47f5-a4fe-e80ca5fc1458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2592591-5951-48c4-96d6-df4c97329e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e615d-c462-4569-b8ef-5dfe09b37b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0f271-2cfa-49a8-8d98-691a090ab5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
